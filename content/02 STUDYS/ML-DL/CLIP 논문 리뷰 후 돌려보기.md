#paper/DL #coding/DL 


> #### '25 ì•„í‚¤í…ì²˜ ìŠ¤í„°ë”” 2ì£¼ì°¨

- [paper link](https://arxiv.org/abs/2103.00020)
- ICML 2021

# Paper
## Abstract
- CV ì‹œìŠ¤í…œì€ ë¯¸ë¦¬ ê²°ì •ëœ ê°ì²´ ë²”ì£¼ì˜ ê³ ì •ëœ ì§‘í•©ì„ ì˜ˆì¸¡í•˜ë„ë¡ í•™ìŠµë¨
- ì´ëŸ° ì œí•œëœ í˜•íƒœì˜ ì§€ë„í•™ìŠµì€ ë‹¤ë¥¸ ì‹œê°ì ì¸ ê°œë…ì„ íŠ¹ì •í•˜ëŠ”ë° ì¶”ê°€ì ì¸ ë°ì´í„°ê°€ í•„ìš”í•˜ë¯€ë¡œ ì¼ë°˜ì„±ê³¼ ìœ ìš©ì„±ì´ ë–¨ì–´ì§
- ì´ë¯¸ì§€ì— ëŒ€í•œ ì›ì‹œ í…ìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ ì§ì ‘ í•™ìŠµí•˜ëŠ” ê²ƒì€ ë” ë„“ì€ ì§€ë„ í•™ìŠµ ì†ŒìŠ¤ë¥¼ í™œìš©í•˜ëŠ” ìœ ë§í•œ ëŒ€ì•ˆ
- Textì™€ Imageì˜ ê´€ê³„ì„±ì„ ëª¨ë¸ë§í•œ ì—°êµ¬!!


## Motivation
- ìì—°ì–´ ì²˜ë¦¬ ë¶„ì•¼ì—ì„œ raw textë¥¼ ì´ìš©í•´ ì‚¬ì „ í•™ìŠµì„ í•˜ëŠ” ë°©ì‹ì€ ê³„ì† ë°œì „í•´ì™”ë‹¤.
- ë°œì „ëœ ì‚¬ì „ í•™ìŠµ ë°©ë²•ì„ ëª¨ë‘ ì ìš©í•œ ëª¨ë¸ì¸ GPT-3ëŠ” ë¼ë²¨ë§ëœ ë°ì´í„°ì…‹ ì—†ì´ë„ ë‹¤ì–‘í•œ íƒœìŠ¤í¬ì—ì„œ ì¢‹ì€ ì„±ëŠ¥ì„ ë‚´ëŠ” ëª¨ë¸ì´ ë˜ì—ˆë‹¤.
- = ìì—°ì–´ ì²˜ë¦¬ ë¶„ì•¼ì—ì„œëŠ” ì ì€ ì–‘ì˜ ë¼ë²¨ì´ ë¶™ì€ ê³ í’ˆì§ˆ ë°ì´í„°ì…‹ë³´ë‹¤, ë§ì€ ì–‘ì˜ ì›¹ ìƒì—ì„œ ìˆ˜ì§‘ëœ ë¼ë²¨ì´ ì—†ëŠ” ë°ì´í„°ê°€ ë” í•™ìŠµì— ìš©ì´í•˜ê²Œ ì‚¬ìš©ëœë‹¤. 
- BUT~! ì»´í“¨í„° ë¹„ì „ ë¶„ì•¼ì—ì„œëŠ” `ì ì€ ì–‘ì˜ ë¼ë²¨ì´ ë¶™ì€ ê³ í’ˆì§ˆ ë°ì´í„°ì…‹`	ì„ ì‚¬ìš©í•œë‹¤.

> ìì—°ì–´ì²˜ë¦¬ ë¶„ì•¼ì²˜ëŸ¼ ì›¹ ìƒì—ì„œ ìˆ˜ì§‘ëœ í…ŒìŠ¤íŠ¸ë¡œë¶€í„° ì‚¬ì „ í•™ìŠµì„ í•˜ëŠ” ë°©ì‹ì„ ì»´í“¨í„° ë¹„ì „ ë¶„ì•¼ì— ì ìš©í•  ìˆ˜ ìˆì„ê¹Œ?!

- 4ì–µ ê°œì˜ [ì´ë¯¸ì§€, í…ìŠ¤íŠ¸] í˜ì–´ë¥¼ ë§Œë“¤ê³  ì´ë¥¼ ConVIRTì˜ ê°„ë‹¨í•œ ë²„ì „ì„ ì´ìš©í•´ í•™ìŠµ 
	= Contrastive Language-Image Pre-training = CLIP


## METHOD

### ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ êµ¬ì¶•
- ImageNetì´ë‚˜ MC-COCO ë°ì´í„°ì…‹ì€ ê³ ì‘ 10ë§Œ ì¥
- YFCC100M 100ë§Œ ì¥ì´ì§€ë§Œ í€„ì´ ì¢‹ì§€ ì•Šì•„ ì „ì²˜ë¦¬ í•˜ë©´ 10ë§Œ ì¥ ì •ë„
- OPENAIì—ì„œëŠ” 4ì–µì¥ì˜ ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ìŒì„ ì¸í„°ë„·ì—ì„œ êµ¬í•¨
- = WebImageText(WIT) ë¼ ëª…ëª…~


### Contrastive Pre-training (ëŒ€ì¡°ì  ì‚¬ì „ í›ˆë ¨)

> #### Contrasitive learning
ë ˆì´ë¸”ë§ ì—†ì´ í•™ìŠµí•˜ëŠ” Self-supervised learning ë°©ë²•ë¡  ì¤‘ í•˜ë‚˜. íŠ¹ì • ì…ë ¥ì„ embedding networkë¥¼ í†µí•´ ì„ë² ë”© ê³µê°„ìœ¼ë¡œ ì´ë™ì‹œí‚¤ê³ , ê°™ì€ classë¼ë©´ ì„ë² ë”© ê°’ì˜ ê±°ë¦¬ë¥¼ ìµœì†Œí™”(d+), ë‹¤ë¥¸ classë¼ë©´ ì„ë² ë”© ê°’ì˜ ê±°ë¦¬ë¥¼ ìµœëŒ€í™”(d-)í•˜ë„ë¡ embedding networkë¥¼ í•™ìŠµí•˜ëŠ” ë°©ë²•.

![](https://velog.velcdn.com/images/adsky0309/post/4162352d-50c6-4667-a7ac-12a6966fdfb9/image.png)



- ëª©í‘œ : ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ ê°„ì˜ ì—°ê´€ì„±ì„ í•™ìŠµí•˜ì!

1. ì´ë¯¸ì§€ ì¸ì½”ë”ëŠ” ì´ë¯¸ì§€ ë°°ì¹˜(I1, I2, I3...)ë¥¼ ì…ë ¥ë°›ì•„ ê° ì´ë¯¸ì§€ì˜ íŠ¹ì§• ë²¡í„°ë¥¼ ì¶”ì¶œ
2. í…ìŠ¤íŠ¸ ì¸ì½”ë”ëŠ” í…ìŠ¤íŠ¸ ë°°ì¹˜(T1, T2, T3...)ë¥¼ ì…ë ¥ë°›ì•„ ê° í…ìŠ¤íŠ¸ì˜ íŠ¹ì§• ë²¡í„°ë¥¼ ì¶”ì¶œ
3. ì´í›„ ê° ì´ë¯¸ì§€ íŠ¹ì§• ë²¡í„°ì™€ í…ìŠ¤íŠ¸ íŠ¹ì§• ë²¡í„°ì˜ ëª¨ë“  ê°€ëŠ¥í•œ ìŒì— ëŒ€í•´ `ìœ ì‚¬ë„`ë¥¼ ê³„ì‚°
4. CLIPì€ ë°°ì¹˜ ë‚´ì—ì„œ ì‹¤ì œë¡œ ì—°ê²°ëœ(image, text) ìŒì˜ ìœ ì‚¬ë„ëŠ” ë†’ì´ê³ , ì˜ëª» ì—°ê²°ëœ ìŒì˜ ìœ ì‚¬ë„ëŠ” ë‚®ì¶”ë„ë¡ í•™ìŠµ
 
> ğŸ¥¨ ì´ë¯¸ì§€ í…ìŠ¤íŠ¸ì—ì„œ ì¶”ì¶œí•œ íŠ¹ì§• ë²¡í„°ëŠ” ì–´ë–¤ í˜•íƒœë¡œ ì €ì¥ë ê¹Œ?
- ì‹¤ìˆ˜ ê°’ìœ¼ë¡œ ì´ë£¨ì–´ì§„ 1ì°¨ì› ë°°ì—´ í˜•íƒœì´ë©°, L2 ì •ê·œí™”ë¥¼ ê±°ì³ ì„ë² ë”© ê³µê°„ì— í‘œí˜„ë¨
- í•´ë‹¹ íŠ¹ì§• ë²¡í„°ëŠ” ì´ë¯¸ì§€ì˜ ì‹œê°ì  íŠ¹ì§•ì„ ë‚˜íƒ€ëƒ„!
- ì‹¤ì œë¡œ ë³´ê³  ì‹¶ë‹¹


### Create dataset classifier from label text

![](https://velog.velcdn.com/images/adsky0309/post/793d92d0-6255-4fd4-898f-6897aec09776/image.png)


- ëª©í‘œ : ì œë¡œìƒ· ë¶„ë¥˜ë¥¼ ìœ„í•´ í…ìŠ¤íŠ¸ ì •ë³´ë¥¼ ì´ìš©í•´ ë¶„ë¥˜ê¸°ë¥¼ ë§Œë“œëŠ” ê²ƒ

1. ë¶„ë¥˜í•˜ê³ ì í•˜ëŠ” ë°ì´í„°ì…‹ì˜ í´ë˜ìŠ¤ ì´ë¦„(ex.plane, car, dog, bird)ì„ í…ìŠ¤íŠ¸ ì¸ì½”ë”ì— ì…ë ¥
2. ê° í´ë˜ìŠ¤ì˜ ì´ë¦„ì€ "A photo of a {object}"ì™€ ê°™ì€ í…œí”Œë¦¿ì„ ì‚¬ìš©! -> ê·¸ëŸ¬ë©´ ë” ì˜ëœë‹¤~~
3. í…ìŠ¤íŠ¸ ì¸ì½”ë”ëŠ” ê° í´ë˜ìŠ¤ì— ëŒ€í•œ í…ìŠ¤íŠ¸ íŠ¹ì§• ë²¡í„°(T1, T2, T3, ..., TN)ë¥¼ ìƒì„±
4. í…ìŠ¤íŠ¸ íŠ¹ì§• ë²¡í„°ë“¤ì€ í•´ë‹¹ í´ë˜ìŠ¤ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ë¶„ë¥˜ê¸°ì˜ ê°€ì¤‘ì¹˜ë¡œ ì‚¬ìš©ë¨


### Use for zero-shot prediction

- ëª©í‘œ : í•™ìŠµ ì—†ì´ ìƒˆë¡œìš´ ì´ë¯¸ì§€ì— ëŒ€í•œ ë¶„ë¥˜ë¥¼ ìˆ˜í–‰í•˜ëŠ” ê²ƒ

1. ë¶„ë¥˜í•˜ê³ ì í•˜ëŠ” ì´ë¯¸ì§€ë¥¼ ì´ë¯¸ì§€ ì¸ì½”ë”ì— ì…ë ¥í•´ ì´ë¯¸ì§€ íŠ¹ì§• ë²¡í„°(I1)ì„ ì¶”ì¶œ


> #### ğŸ¥¨CLIPì´ ì´ë¯¸ì§€ë¥¼ ë¯¸ë¦¬ í•™ìŠµí•˜ì§€ ì•Šê³ ë„ ìƒˆë¡œìš´ í´ë˜ìŠ¤ë¥¼ ì¸ì‹í•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ì€ ì–´ë””ì„œ ë¹„ë¡¯ëœ ê±¸ê¹Œ?
> 
> 1. ëŒ€ì¡° í•™ìŠµ(Contrastive Learning)
- ë°©ëŒ€í•œ ì–‘ì˜ (ì´ë¯¸ì§€, í…ìŠ¤íŠ¸) ìŒ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•´ ëŒ€ì¡° í•™ìŠµì„ ìˆ˜í–‰
- => ì´ ê³¼ì •ì—ì„œ ëª¨ë¸ì€ ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ ê°„ì˜ ì˜ë¯¸ì  ì—°ê´€ì„±ì„ í•™ìŠµ
>2. ìì—°ì–´ ì§€ë„(Natural Language Supervision)
- CLIPì€ ì´ë¯¸ì§€ì— ëŒ€í•œ í…ìŠ¤íŠ¸ ì„¤ëª…ì„ ì§ì ‘ì ì¸ ì§€ë„ ì‹ í˜¸ë¡œ í™œìš©
- = ì´ë¯¸ì§€ì˜ ê°ì²´, ì†ì„±, ìŠ¤íƒ€ì¼ ë“±ì— ëŒ€í•œ í…ìŠ¤íŠ¸ ì •ë³´ë¥¼ ì´ìš©í•´ í•™ìŠµ!
- "A photo of a [object]"ì™€ ê°™ì€ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ì‚¬ìš©í•´ í…ìŠ¤íŠ¸ ì„¤ëª…ì„ ìƒì„±í•˜ê³ , ì´ë¥¼ í†µí•´ ë‹¤ì–‘í•œ í´ë˜ìŠ¤ì— ëŒ€í•œ ì¼ë°˜í™” ëŠ¥ë ¥ í–¥ìƒ
> 3. ì˜ë¯¸ì  ì„ë² ë”© ê³µê°„(Semantic Embedding Space)
- CLIPì€ ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ë¥¼ ê³µí†µì˜ ì˜ë¯¸ì  ì„ë² ë”© ê³µê°„ì— í‘œí˜„
- => ë¹„ìŠ·í•œ ì˜ë¯¸ë¥¼ ê°€ì§„ ì´ë¯¸ì§€ì™€ í…ŒìŠ¤íŠ¸ëŠ” ì„œë¡œ ê°€ê¹Œì´ ìœ„ì¹˜í•˜ê²Œ ë¨
- ìƒˆë¡œìš´ í´ë˜ìŠ¤ì— ëŒ€í•œ í…ìŠ¤íŠ¸ ì„¤ëª…ì´ ì£¼ì–´ì§€ë©´, CLIPì€ í•´ë‹¹ í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”© ê³µê°„ì— íˆ¬ìš©í•˜ê³ , ê°€ì¥ ê°€ê¹Œìš´ ì´ë¯¸ì§€ë¥¼ ì°¾ìŒ
> => í•™ìŠµ ë°ì´í„°ì…‹ì— ì—†ëŠ” ìƒˆë¡œìš´ í´ë˜ìŠ¤ì— ëŒ€í•´ì„œë„ ì´ë¯¸ì§€ ë¶„ë¥˜ë¥¼ ìˆ˜í–‰í•  ìˆ˜ ìˆìŒ!!
>
> = `ë¹„ìœ ` : ì™¸êµ­ì–´ë¥¼ ë°°ìš¸ ë–„ ë‹¨ì–´ì™€ ê·¸ë¦¼ì„ í•¨ê¼ ë³´ë©´ì„œ ë‹¨ì–´ì˜ ì˜ë¯¸ë¥¼ í•™ìŠµ


> #### ğŸ¥¯ í•™ìŠµ ë°ì´í„°ì…‹ì˜ í¬ê¸°ê°€ í´ ìˆ˜ë¡ ì„±ëŠ¥ì´ ê³„ì† í–¥ìƒë ê¹Œ?
- YES : ê³¼ì í•©ì„ ë°©ì§€í•˜ê³  ë” ë§ì€ ì˜ë¯¸ì˜ ì—°ê´€ì„±ì„ í•™ìŠµí•  ìˆ˜ ìˆìŒ
- NO : í•˜ì§€ë§Œ ë°ì´í„° í’ˆì§ˆì´ ë‚®ê±°ë‚˜ ëª¨ë¸ì˜ ìš©ëŸ‰ì´ ë¶€ì¡±í•˜ë©´ ì„±ëŠ¥ í–¥ìƒí­ì´ ì¤„ì–´ë“¤ ê²ƒ!


## Pseudo code

![](https://velog.velcdn.com/images/adsky0309/post/d18c99c2-f8f3-422a-8f2b-39bef60825e9/image.png)

- `Image encoder` :  ResNetì´ë‚˜ Vision Transformer ì‚¬ìš©
- `text encoder` :  Transformer ì‚¬ìš©(CBOWëŠ” ë­ì§€)
- `I[n, h, w, c]` : ì´ë¯¸ì§€ì˜ ë¯¸ë‹ˆ ë°°ì¹˜
    - `n` : ë°°ì¹˜ í¬ê¸°, `h` : ë†’ì´, `w` : ë„ˆë¹„, `c` : ì±„ë„ ìˆ˜
- `T[n,1]` : í…ìŠ¤íŠ¸ì˜ ë¯¸ë‹ˆ ë°°ì¹˜
    - `n` : ë°°ì¹˜ í¬ê¸°, `1` : ì‹œí€€ìŠ¤ ê¸¸ì´

> #### ğŸ¥¨ ë°°ì¹˜ vs ë¯¸ë‹ˆ ë°°ì¹˜
>![](https://velog.velcdn.com/images/adsky0309/post/f4f05b72-39b9-4e22-bb9e-4e12edf7b5f3/image.png)
>
> **ë°°ì¹˜(Batch)**
- ì „ì²´ í›ˆë ¨ ë°ì´í„°ì…‹ì„ í•œ ë²ˆì˜ ë°˜ë³µ(Iteration)ì—ì„œ ëª¨ë¸ì— ì…ë ¥í•´ í•™ìŠµí•˜ëŠ” ë°©ì‹
	= ëª¨ë¸ì´ í•œ ë²ˆ ì—…ë°ì´íŠ¸ í•  ë•Œ ì „ì²´ ë°ì´í„°ë¥¼ ì‚¬ìš©
- ì¥ì  : 1) ì •í™•í•œ Gradient ê³„ì‚° 2) ìˆ˜ë ´ ì•ˆì •ì„±
- ë‹¨ì  : 1) ë†’ì€ ê³„ì‚° ë¹„ìš© 2) í•™ìŠµ ì†ë„ ì €í•˜
>
> **ë¯¸ë‹ˆë°°ì¹˜(Mini-batch)**
- ì „ì²´ í›ˆë ¨ ë°ì´í„°ì…‹ì„ ì‘ì€ ë¶€ë¶„ì§‘í•©ìœ¼ë¡œ ë‚˜ëˆ„ì–´, ê° ë¯¸ë‹ˆë°°ì¹˜ë¥¼ ì‚¬ìš©í•´ ëª¨ë¸ì„ ì—…ë°ì´íŠ¸í•˜ëŠ” ë°©ì‹
- ì¥ì  : 1) ë‚®ì€ ê³„ì‚° ë¹„ìš© 2) ë¹ ë¥¸ í•™ìŠµ ì†ë„ 3) Regularization : Gradientì— ë…¸ì´ì¦ˆë¥¼ ì¶”ê°€í•´ Regularization íš¨ê³¼ë¥¼ ì£¼ì–´ ëª¨ë¸ì˜ ì¼ë°˜í™” ì„±ëŠ¥ì„ í–¥ìƒ 4) Local Minima íƒˆì¶œ
- ë‹¨ì  : 1) ë¶ˆì•ˆì •í•œ Gradient ê³„ì‚° 2) ì¶”ê°€ì ì¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ í•„ìš”

- `W_i[d_i, d_e]` : ì´ë¯¸ì§€ë¥¼ ì„ë² ë”©í•˜ëŠ” í•™ìŠµëœ projection
    - ì´ë¯¸ì§€ë¥¼ ì„ë² ë”©í•œë‹¤ = ë¯¸ì§€ë¥¼ ë²¡í„° í˜•íƒœë¡œ í‘œí˜„í•œë‹¤.
    - í•™ìŠµëœ Projection : ëª¨ë¸ì´ ë°ì´í„°ë¥¼ ê°€ì¥ ì˜ í‘œí˜„í•  ìˆ˜ ìˆë„ë¡ Projection ë°©ë²•ì„ ìŠ¤ìŠ¤ë¡œ ì°¾ì•„ëƒ„.
   - ì£¼ë¡œ Fully Connected Layerë‚˜ ì„ í˜• ë³€í™˜ì„ í†µí•´ projectionì„ êµ¬í˜„í•˜ë©°, ì´ Layerì˜ ê°€ì¤‘ì¹˜ë“¤ì´ í•™ìŠµì„ í†µí•´ ì¡°ì •ë¨
   - `d_i` : ì´ë¯¸ì§€ íŠ¹ì§•ì˜ ì°¨ì›, `d_e` : ì„ë² ë”© ê³µê°„ì˜ ì°¨ì›
- `W_t[d_t, d_e]` : í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©í•˜ëŠ” í•™ìŠµëœ projection
- `t`: ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ì—ì„œ ë¡œì§“ì˜ ë²”ìœ„ë¥¼ ì¡°ì ˆí•˜ëŠ” í•™ìŠµ ê°€ëŠ¥í•œ ì˜¨ë„ íŒŒë¼ë¯¸í„°


- extract feature representations of each modality : ê° modallityì—ì„œ íŠ¹ì§• representationì„ ì¶”ì¶œ
    - `I_f = image_encoder(I) #[n, d_i]` : ì´ë¯¸ì§€ ì¸ì½”ë”ë¥¼ í†µí•´ ì´ë¯¸ì§€ íŠ¹ì§• `I_f` ì¶”ì¶œ
    	- `n` : ë°°ì¹˜í¬ê¸°, `d_t` : í…ìŠ¤íŠ¸ íŠ¹ì§• ì°¨ì›
    - `T_f = text_encoder(T) #[n, d_t]` : í…ìŠ¤íŠ¸ ì¸ì½”ë”ë¥¼ í†µí•´ í…ìŠ¤íŠ¸ íŠ¹ì§• `T_f` ì¶”ì¶œ
    	- `n` : ë°°ì¹˜í¬ê¸°, `d_t` : í…ìŠ¤íŠ¸ íŠ¹ì§• ì°¨ì›

- joint multimodal embedding [n, d_e] : ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ë¥¼ joint multimodal ì„ë² ë”© ê³µê°„ìœ¼ë¡œ ì„ë² ë”©
    - `I_e : l2_normalize(np.dot(I_f, W_i), axis=1)` : `I_f` : ì´ë¯¸ì§€ íŠ¹ì§•ì„ `W_i` : ê°€ì¤‘ì¹˜ í–‰ë ¬ë¡œ íˆ¬ì˜í•œ í›„ L2 ì •ê·œí™” ìˆ˜í–‰í•´ì„œ ì´ë¯¸ì§€ ì„ë² ë”©ì„ ì–»ìŒ
    - `T_e : l2_normalize(np.dot(T_f, W_t), axis=1)`

- scaled pairwise cosine similarities [n, n] : ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ ì„ë² ë”© ê°„ì˜ pairwise ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•˜ê³  ì˜¨ë„ íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ìš©í•´ ìŠ¤ì¼€ì¼ë§
    - `logits = np.dor(I_e, T_e.T) * np.exp(t)` : ì´ë¯¸ì§€ ì„ë² ë”© `I_e`ì™€ í…ìŠ¤íŠ¸ ì„ë² ë”© `T_e` ê°„ì˜ í–‰ë ¬ ê³±ì…ˆì„ í†µí•´ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•˜ê³ , ì˜¨ë„ íŒŒë¼ë¯¸í„°ì˜ ì§€ìˆ˜ í•¨ìˆ˜ë¥¼ ê³±í•´ ë¡œì§“ì„ ì–»ê¸°
    
> #### ğŸ¥¨ ë¡œì§“ì„ ì–»ëŠ”ë‹¤?
- ë¡œì§“(Logit)ì€ í™•ë¥  pë¥¼ odds(ì„±ê³µ í™•ë¥  ëŒ€ ì‹¤íŒ¨ í™•ë¥ ì˜ ë¹„ìœ¨)ë¡œ ë³€í™˜í•œ ë‹¤ìŒ, oddsì— ë¡œê·¸ë¥¼ ì·¨í•œ ê°’
- í™•ë¥ ì„ ëª¨ë¸ë§í•˜ê¸° ìœ„í•´ ì‚¬ìš©ë˜ëŠ” í•¨ìˆ˜ë¡œ, 0ê³¼ 1 ì‚¬ì´ì˜ í™•ë¥  ê°’ì„ ì‹¤ìˆ˜ ì „ì²´ ë²”ìœ„ë¡œ í™•ì¥ì‹œì¼œ ì¤Œ
>
> $$
logit(p)=log(\frac{p}{1-p}) $$
>
> - ë¡œì§“ ê°’ì´ 0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ëª¨ë¸ì€ ì˜ˆì¸¡ì— ëŒ€í•´ ë¶ˆí™•ì‹¤í•¨
#### CLIPì—ì„œ ë¡œì§“ì„ ì–»ëŠ” ì´ìœ 
- ë¡œì§“ì€ ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ ì„ë² ë”© ê°„ì˜ ìœ ì‚¬ë„ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì ìˆ˜ì´ë©°, ë†’ì„ ìˆ˜ë¡ ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ê°€ ì˜ ë§ëŠ”ë‹¤ê³  íŒë‹¨
- ì˜¨ë„ íŒŒë¼ë¯¸í„° të¥¼ ì´ìš©í•´ ë¡œì§“ì˜ ìŠ¤ì¼€ì¼ì„ ì¡°ì •í•¨ìœ¼ë¡œì¨, ëª¨ë¸ì€ ì˜¬ë°”ë¥¸ ìŒì„ ë” ì˜ ì‹ë³„í•˜ê³  ì˜ëª»ëœ ìŒì„ ë” ì˜ êµ¬ë³„í•  ìˆ˜ ìˆìŒ
- ì´í›„ ë¡œì§“ì€ Softmax í•¨ìˆ˜ì˜ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš© -> ë¡œì§“ ê°’ì„ í™•ë¥  ë¶„í¬ë¡œ ë³€í™˜í•˜ì—¬ ê° í´ë˜ìŠ¤ì— ëŒ€í•œ í™•ë¥ ì„ ì–»ì„ ìˆ˜ ìˆìŒ

- symmetric loss function : ëŒ€ì¹­ ì†ì‹¤ í•¨ìˆ˜
    - `labels = np.arange(n)`  : 0ë¶€í„° n-1ê¹Œì§€ ìˆ«ìë¥¼ ë‹´ì€ ë°°ì—´ì„ ìƒì„±
    - `loss_i = cross_entropy_loss(logits, labels, axis=0)`
    	- `cross_entropy_loss` : êµì°¨ ì—”íŠ¸ë¡œí”¼ ì†ì‹¤ í•¨ìˆ˜ ê³„ì‚°. ë‘ í™•ë¥  ë¶„í¬ ê°„ì˜ ì°¨ì´ë¥¼ ì¸¡ì •í•˜ëŠ”ê²Œ ì‚¬ìš©. ì—¬ê¸°ì„œëŠ” ì˜ˆì¸¡ëœ ìœ ì‚¬ë„(logits)ì™€ ì‹¤ì œ ë ˆì´ë¸”(labels) ê°„ì˜ ì°¨ì´ë¥¼ ê³„ì‚°
        - `logits` : ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ ì„ë² ë”© ê°„ì˜ ìœ ì‚¬ë„ ì ìˆ˜ = ì–¼ë§ˆë‚˜ ì˜ ë§¤ì¹­ë˜ëŠ”ì§€
        - `labels` : ì •ë‹µ ë ˆì´ë¸”
        - `axis=0` : logitsì˜ 0ë²ˆì§¸ ì¶•ì„ ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°. ì¦‰, ê° ì´ë¯¸ì§€ì— ëŒ€í•œ ì†ì‹¤ ê³„ì‚°
    - `loss_t = cross_entropy_loss(logits, labels, axis=1)` : ìœ„ì™€ ë™ì¼í•˜ì§€ë§Œ í…ìŠ¤íŠ¸ì— ëŒ€í•œ ì†ì‹¤ì„ ê³„ì‚°
    - `loss = (loss_i + loss_t)/2` : ë‘ ì†ì‹¤ì˜ í‰ê· 
    - ì´ë ‡ê²Œ ì†ì‹¤ í•¨ìˆ˜ë¥¼ ì •ì˜


### Training

- 5ê°œì˜ ResNetsì™€ 3ê°œì˜ ViTë¥¼ ê°€ì§€ê³  train

---
## Result
ì‹¤í—˜ì„ ì •ë§ ì—„ì²­ë‚˜ê²Œ ë§ì´ í•˜ì‹¬

![](https://velog.velcdn.com/images/adsky0309/post/9fdf30aa-f7b1-453f-be59-cb9a2474fd4b/image.png)

- xì¶• (Forward-pass GFLOPs/image) : ëª¨ë¸ì´ ì´ë¯¸ì§€ í•˜ë‚˜ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë° í•„ìš”í•œ ê³„ì‚°ëŸ‰. ì˜¤ë¥¸ìª½ìœ¼ë¡œ ê°ˆìˆ˜ë¡ ê³„ì‚°ëŸ‰ì´ ë§ê³  ë¬´ê±°ìš´ ëª¨ë¸.
- yì¶•(Average Score %): ëª¨ë¸ì˜ ì„±ëŠ¥
- `Linear Probe` í‰ê°€ : ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ì˜ ì¸ì½”ë” ë¶€ë¶„(íŠ¹ì§• ì¶”ì¶œê¸°)ì€ ê³ ì •ì‹œí‚¤ê³ , ê°„ë‹¨í•œ ì„ í˜• ë¶„ë¥˜ê¸°ë¥¼ ì¶”ê°€ë¡œ í•™ìŠµì‹œì¼œ ì„±ëŠ¥ì„ í‰ê°€í•˜ëŠ” ë°©ì‹.
	- ëª¨ë¸ì´ ì‚¬ì „ í•™ìŠµ ë‹¨ê³„ì—ì„œ ë°ì´í„°ì˜ ë³¸ì§ˆì ì¸ íŠ¹ì§•ì„ ì–¼ë§ˆë‚˜ ì˜ í•™ìŠµí–ˆëŠ”ì§€

> #### ğŸ¥¨ Linear Probing
ê°€ì¥ ë‹¨ìˆœí•œ ë¶„ë¥˜ê¸°(ex. íŠ¹ì§•ë§Œ ë³´ê³  ì‚¬ì§„ì„ ë¶„ë¥˜í•˜ëŠ” ì•Œë°”ìƒ)ë¥¼ ë¶™ì—¬ì„œ í…ŒìŠ¤íŠ¸ í–ˆì„ ë•Œ ì„±ëŠ¥ì´ ì–¼ë§ˆë‚˜ ì˜ ë‚˜ì˜¤ëŠ”ì§€ í…ŒìŠ¤íŠ¸í•´ì„œ ì›ë˜ ìˆëŠ” ëª¨ë¸(ex. ì‚¬ì§„ì˜ íŠ¹ì§•ì„ ë½‘ì•„ë‚´ëŠ” ì „ë¬¸ê°€)ì´ ì–¼ë§ˆë‚˜ ë°ì´í„°ë¥¼ ì˜ ì´í•´í•˜ê³  í•µì‹­ íŠ¹ì§•ì„ ì˜ ë½‘ì•„ë‚´ëŠ”ì§€ í‰ê°€í•˜ëŠ” ë°©ë²•!


- Zero-shot transferì˜ ê²½ìš° ì´ë¯¸ì§€ ë¶„ë¥˜ì—ì„œ ì••ë„ì ì¸ ì„±ëŠ¥ì„ ë‚¼ ìˆ˜ ìˆìŒ



---
# ëª¨ë¸ ëŒë ¤ë³´ê¸°

```
pip install git+https://github.com/openai/CLIP.git
```
ì¼ë‹¨ clip ëª¨ë¸ì„ ì„¤ì¹˜í•´ì£¼ê³ 


```python
import torch
import clip
from PIL import Image

device = "cuda" if torch.cuda.is_available() else "cpu"
model, preprocess = clip.load("ViT-B/32", device=device) # preprocess í•¨ìˆ˜
```

modelì€ ViT ëª¨ë¸ ê°€ì ¸ì˜´!
preprocess í•˜ëŠ” í•¨ìˆ˜ëŠ” ViTì—ê²Œ íŠ¹í™”ëœ íŒŒì´í”„ë¼ì¸!

```python
# ì´ë¯¸ì§€ ë¡œë“œ ë° ì „ì²˜ë¦¬
image = preprocess(Image.open("danbibest.jpg")).unsqueeze(0).to(device)
queries = [
    "basketball player", "a tylenol ER", "woman basketball player dribbling", "a runner", "so many basketball players"
]
text = clip.tokenize(queries).to(device) # torch.Size([5, 77])
```

- preprocess(...) : CLIP ëª¨ë¸ì„ ë¡œë“œí•  ë•Œ í•¨ê»˜ ì œê³µí•˜ëŠ” í•¨ìˆ˜
    - ì´ë¯¸ì§€ë¥¼ CLIP ëª¨ë¸ì´ í•™ìŠµëœ íŠ¹ì • í¬ê¸°ë¡œ ì¡°ì •
    - ì´ë¯¸ì§€ë¥¼ pytorch í…ì„œ í˜•íƒœë¡œ ë³€í™˜
    - ì´ë¯¸ì§€ í”½ì…€ ê°’ì„ íŠ¹ì • í‰ê· ê³¼ í‘œì¤€í¸ì°¨ë¡œ ì •ê·œí™”!
- unsqueeze(0) : ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ í…ì„œëŠ” ë³´í†µ [c, h, w]ì¸ë° ëª¨ë¸ì€ batchë‹¨ìœ„ë¡œ ë°›ìœ¼ë¯€ë¡œ ì•ì— 1ì¶”ê°€
- [5,77] : í…ìŠ¤íŠ¸ 5ê°œì— ëŒ€í•´ ê°ê° 77ê°œì˜ í† í° IDë¥¼ ê°€ì§„ë‹¤ëŠ” ì˜ë¯¸ : ë‚´ê°€ queriesì— 5ê°œë¥¼ ë„£ì—ˆìœ¼ë‹ˆê¹Œ!


ì°¸ê³ ë¡œ ë‚´ê°€ ì“´ ì‚¬ì§„ì€ í‚¹ë‹¨ë¹„
![](https://velog.velcdn.com/images/adsky0309/post/1e4744de-2d8a-49fa-911c-c350f3592924/image.png)

```python
with torch.no_grad():
    image_features = model.encode_image(image) # [1. embed_dim] = [1, 512]
    text_features = model.encode_text(text)  # [5,512] <- [5,77]ì—ì„œ ë³€í™˜

    logits_per_image, logits_per_text = model(image, text)
    probs = logits_per_image.softmax(dim=-1).cpu().numpy()
```

ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ì˜ íŠ¹ì„±ì„ ê°€ì§€ê³  ì™€ì¤€ë‹¤

- ì²˜ìŒì— í…ìŠ¤íŠ¸ì˜ í† í° ID ì‹œí€€ìŠ¤ëŠ” [5,77]!
- í…ìŠ¤íŠ¸ ì¸ì½”ë”ì˜ ì—­í• ì€ ì…ë ¥ìœ¼ë¡œ ë°›ì€ í† í° ID ì‹œí€€ìŠ¤ [5,77]ì„ ë¶„ì„í•´ì„œ ê° í…ìŠ¤íŠ¸ê°€ ë‹´ê³  ìˆëŠ” ì‹¤ì œ ì˜ë¯¸ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ê³ ì •ëœ í¬ê¸°ì˜ ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” ê²ƒ
- [5,77] -> [5,77, ë‚´ë¶€ì°¨ì›] -> (ì „ì²´ ì‹œí€€ìŠ¤ í•˜ë‚˜ë¡œ ì••ì¶•) -> [5, ë‚´ë¶€ì°¨ì›] -> (projection. ëŒ€í‘œ ë²¡í„°ë¥¼ ì´ë¯¸ì§€ ì„ë² ë”©ê³¼ ë™ì¼í•œ ìµœì¢… ì„ë² ë”© ì°¨ì›ìœ¼ë¡œ ë§¤í•‘í•˜ëŠ” ì„ í˜• ë ˆì´ì–´ í†µê³¼) -> [5,512]
- ê²°êµ­ 5ê°œì˜ í…ìŠ¤íŠ¸ ê°ê°ì— ëŒ€í•œ 512ì°¨ì›ì˜ ì˜ë¯¸ë¥¼ ë‹´ì€ ë²¡í„°ê°€ ë¨


```python
# normalized features
# ìœ ì‚¬ë„ ê³„ì‚°ì— ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ ê° íŠ¹ì§• ë²¡í„°ì˜ í¬ê¸°ë¥¼ 1ë¡œ ë§Œë“¦
image_features = image_features / image_features.norm(dim=1, keepdim=True) #shape:[1,1]
text_features = text_features / text_features.norm(dim=1, keepdim=True) #shape:[5,1]

# ìœ ì‚¬ë„ ê³„ì‚° ë° ìŠ¤ì¼€ì¼ë§
logit_scale = model.logit_scale.exp()
logits_per_image = logit_scale * image_features @ text_features.t()  # (1, 512) @ (512, 5)
logits_per_text = logits_per_image.t() # í…ìŠ¤íŠ¸ ê´€ì ì—ì„œì˜ ìœ ì‚¬ë„ [5,1]


```

ì´ë¯¸ì§€ íŠ¹ì§• ë²¡í„°ì™€ í…ìŠ¤íŠ¸ íŠ¹ì§• ë²¡í„°ë“¤ì„ ì‚¬ìš©í•´ ì´ë¯¸ì§€ì™€ ê° í…ìŠ¤íŠ¸ ì„¤ëª… ê°„ì˜ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•˜ê³  í™•ì¸í•˜ëŠ” ë¶€ë¶„!
- `logit_scale=model.logit_scale.exp()` : ëª¨ë¸ ë‚´ë¶€ì˜ í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„°ì¸ `logit_scale`ì— ì§€ìˆ˜ í•¨ìˆ˜ `exp()` ì ìš©
- ê·¸ë¦¬ê³  ì •ê·œí™”ëœ ì´ë¯¸ì§€ ë²¡í„°[1,512]ì™€ ì „ì¹˜ëœ í…ìŠ¤íŠ¸ ë²¡í„°[512,5(=í…ìŠ¤íŠ¸ ê°œìˆ˜)] ê°„ì˜ í–‰ë ¬ ê³±ì…ˆ ìˆ˜í–‰

```python

print(logits_per_image.shape, logits_per_text.shape)
print(logits_per_image) # ì›ì‹œ ìœ ì‚¬ë„ ì ìˆ˜
print(logits_per_image.softmax(dim=-1)) #softmax ì ìš©

---
>>> torch.Size([1, 5]) torch.Size([5, 1])
>>> tensor([[26.5781, 16.3438, 30.6094, 20.7812, 19.9844]], device='cuda:0',
       dtype=torch.float16, grad_fn=<MmBackward0>)
>>> tensor([[1.7441e-02, 6.5565e-07, 9.8242e-01, 5.2989e-05, 2.3901e-05]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SoftmaxBackward0>)
```

ìœ ì‚¬ë„ ê³„ì‚° ê²°ê³¼!

```python
# ìµœì¢… í™•ë¥  ì¶”ì¶œ
confidences = logits_per_image.softmax(dim=-1).detach().cpu().numpy().ravel()
for confidence, query in zip(confidences, queries):
    print(query, ":", confidence)
```

![](https://velog.velcdn.com/images/adsky0309/post/aceb789e-f45f-4721-925c-4ec1e2500325/image.png)


basketball playerë„ ì ìˆ˜ê°€ ë‚®ë„¤...ì‹ ê¸°

![](https://velog.velcdn.com/images/adsky0309/post/4bf62419-6257-497b-8afc-dc38f8362227/image.png)

woman ë„£ìœ¼ë‹ˆê¹Œ ì ìˆ˜ í™• ëŠ˜ì–´ë‚¨...ì‹ ê¸°22..


#### ëª¨ë¸ êµ¬ì¡° í™•ì¸
```
VisionTransformer(
  (conv1): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)
  (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  (transformer): Transformer(
    (resblocks): Sequential(
      (0): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
        )
        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=768, out_features=3072, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=3072, out_features=768, bias=True)
        )
        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (1): ResidualAttentionBlock(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
        )
        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=768, out_features=3072, bias=True)
          (gelu): QuickGELU()
...
    )
  )
  (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
)
```
```
Transformer(
  (resblocks): Sequential(
    (0): ResidualAttentionBlock(
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
      )
      (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=512, out_features=2048, bias=True)
        (gelu): QuickGELU()
        (c_proj): Linear(in_features=2048, out_features=512, bias=True)
      )
      (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (1): ResidualAttentionBlock(
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
      )
      (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=512, out_features=2048, bias=True)
        (gelu): QuickGELU()
        (c_proj): Linear(in_features=2048, out_features=512, bias=True)
      )
      (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
...
      (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
  )
)
```

ë~