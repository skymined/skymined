---
tags:
  - research
created: 2026-03-01T14:32:00
---

3D 딥러닝이란 3차원 공간에 존재하는 데이터를 이해하기 위한 딥러닝 방법들을 말한다. 

2D 딥러닝의 데이터 형태는 $x \in R^{HXWXC}$로, 규칙적인 격자를 가지고 있고 픽셀 간의 간격이 일정해 convolution이 잘 정의된다. 반면에 3D 딥러닝의 경우에는 point cloud, voxel grid, mesh, implicit field 등 다양한 형태로 표현할 수 있으며 대부분은 격자가 아니다. 

때문에 우리는 3D 딥러닝을 3차원 공간에 존재하는 구조적 데이터를 위한 표현 학습 문제라고 볼 수 있다. 

3D 데이터는 1) 순서도 없고 2) 간격도 불규칙하고 3) 회전도 존재하고 4) 공간 대부분이 비어있는 희소성이라는 특징이 있는데, 이렇게 3D 공간을 어떻게 수학적으로 표현할 것인가? 라는 질문에 답하기 위해 다양한 접근법들이 생겼다.

오늘은 다양한 접근법들을 간단하게 <font color="#de7802">찍먹</font>해 보려고 한다.

## 1️⃣ projection-based 방법

-   3D point cloud를 2D 이미지로 투영한 뒤 2D CNN을 사용하는 방법
-   장점: 2D CNN을 그대로 사용할 수 있음, 학습이 안정적임
-   단점: 3D 기하 정보가 손실됨, 가려짐 문제가 발생함, 투영 방향에 민감함, sparse 구조를 활용하지 못함

### 1\. multi-view projection

-   3D 객체를 여러 각도에서 렌더링하고 여러 2D 이미지를 생성한다.
-   그 다음 각 이미지에 CNN을 적용하고
-   feature fusion

### 2\. TangentConv

-   각 점 주변의 표면을 접평면에 펼침
-   작은 2D 패치처럼 처리

## 2️⃣ Voxel-based 방법

-   3D 공간을 정육면체 격자로 나누고 3D CNN을 적용
-   공간을 32X32X32 등으로 나누고 각 voxel에 점이 있으면 1 → 3D convolution 수행
-   장점: CNN 구조 그대로 확장 가능, local spatial modeling 좋음
-   단점: 1) 메모리 폭발 2) 대부분 empty한 공간 3) 정밀한 구조가 사라짐

## 3️⃣ Sparse Voxel 방법

-   비어있지 않은 voxel만 convolution 수행
-   방식
    -   sparse tensor 사용
    -   coordinate 기반 indexing
    -   octree 구조 등
-   장점
    -   메모리 절감
    -   대규모 scene 가능
-   단점
    -   여전히 grid 기반
    -   양자화는 존재 → 정밀한 구조 사라짐

## 4️⃣ Point-based 방법

-   point cloud를 그대로 set으로 처리함
-   장점: 순열 불변, 양자화 없음, 메모리 효율적
-   단점: 초기 PointNet은 local geometry가 약하고 global pooling은 거침

### 1\. PointNet

-   각 점에 MLP하고 global max pooling

### 2\. PointNet++

-   local grouping을 진행

## 5️⃣ Graph-based 방법

-   point들을 그래프로 연결하고 message passing을 수행함 → local 관계를 더 잘 모델링하려고
-   방식
    -   KNN graph 생성
    -   edge feature 생성
    -   graph convolution 수행
    
-   장점
    -   local relational modeling 강함
    -   topology-aware
-   단점
    -   그래프 생성 비용
    -   dynamic graph는 계산량 큼

> point cloud는 원래  
> $$  {(x_i,p_i)}^N\_{i=1} $$  
> 이때 $p\_i$는 좌표고 $x\_i$는 feature  
> graph-based의 경우 점은 노드고 점들 사이의 관계는 엣지라고 생각함  
> $$   G=(V,E)   $$  
> 이때 V는 점들이고 E는 점들 사이의 연결임

스텝은 다음과 같다.

**Step1 그래프 만들기**  
가장 흔한 방법은 kNN graph인데, 가장 가까운 k개의 점을 찾아서 edge를 생성하는 것이다. 이렇게 하면 국소 구조가 생긴다  
**Step2 edge feature를 정의**  
중요한 건 단순히 이웃 평균을 내는 것이 아니라 관계 함수를 학습하는 것으로, 대표적으로 DGCNN이 있다.  
$$  
e\_{ij}=h\_{\\theta}(x\_i, x\_j-x\_i)  
$$

> 🧐 edge feature를 정의한다?  
> 먼저 아무 생각 없이 평균을 낼 경우 그냥 이웃들의 평균 feature고 관계라는 것은 없음  
> 관계를 넣는다는 것은, 이웃 j가 i에게 영향을 줄 때, 그 영향이 i와 j의 관계에 따라 달라진다는 것으로, j가 i의 위쪽에 있다던가 하는 것들이다.  
> 그래서 등장하는 개념이 $$e_{ij}=relation(x_i, x_j, p_i, p_j)$$  
> 예를 들어 DGCNN의 경우에는 $$e_{ij}=h_{\theta}(x_i, x_j,-x_i)$$로 이웃 j가 중심 i가 얼마나 다른지를 MLP가 학습한다.

**Step3 메시지 패싱**  
각 노드가 이웃들로부터 메시지를 받아서 자기 표현을 업데이트하는 과정으로 graph neural network라고도 한다.

여기서 message라는 건 각 노드가 '내 이웃들은 나에게 어떤 영향을 주는가?'의 영향을 계산한 결과다.

예를 들어, 의자 다리의 한 점이라고 봤을 때, 각 점들은 중간 점에게 '나는 위에 있어', '나는 경계야', '나는 바닥 쪽이야'라는 메시지를 던지고, 이 메시지들을 모드면 나는 의자 다리의 일부구나~ 라는 것을 알 수 있게 된다. 

## 6️⃣ Continuous Convolution 방법

-   격자 없이 좌표 기반으로 연속적인 convolution을 정의함
-   voxel 양자화 없이 convolution을 쓰기 위해 등장함
-   대표적으로는 PointConv, KPConv, SpiderCNN이 있음
-   장점
    -   좌표 기반임
    -   양자화, 격자 필요 없음
-   단점
    -   kernel 설계가 복잡하고 구현 난이도가 높음

> 👀 일반 CNN과의 비교  
> 일반 CNN의 경우에 커널 위치가 고저되어 있으나 continuous의 경우 커널 위치가 좌표 기반이라  
> $$  
> w(\Lambda x, \Lambda y, \Lambda z)  
> $$  
> 가 된다. 직관적으로 보자면 격자 CNN은 '왼쪽 위 픽셀의 weight는 0.2'라고 한다면 continuous convolution은 '거리 3cm 위쪽 방향 점의 weight는 0.2'가 됨.

## 7️⃣ Transformer-based (Point Transformer)

-   self-attention을 local하게 적용한 것
-   kNN local attention, vector attention, relative position encoding 등이 있음
-   point transformer 논문을 읽어보며 자세히 알아볼 것

| 방법 | gird 필요 | 양자화 | local modeling | global modeling |
| --- | --- | --- | --- | --- |
| Projection | 2D grid | O | 약함 | 보통 |
| Voxel | 3D grid | O | 강함 | 보통 |
| Sparse voxel | 3D grid | O | 강함 | 보통 |
| PointNet | X | X | 약함 | 강함 |
| Graph | X | X | 매우 강함 | 깊이에 의존 |
| Continuous conv | X | X | 강함 | 깊이에 의존 |
| Transformer | X | X | 강함 | 계층적 |