---
tags:
  - robotics
type:
  - PAPER
---
![[Pasted image 20260228185449.png]]

## Brief

Hand + Tool-use 라는 키워드 조합을 만족시킨, 그것도 젓가락이라는 굉장히 복합한 tool을 이용해 물체를 옮기는 작업을 수행한 논문이다. 모션 캡처 데이터가 없이 AI가 스스로 물리적으로 타당한 젓가락 쥐는 법을 찾아내고, 다양한 형태의 물체를 실시간으로 조작하게 만드는 것을 목표로 했고, 이를 위해 문제를 두 단계로 나눴다.

-   젓가락을 안정적으로 잡을 수 있는 다양한 파지법(=grip)을 찾자
-   해당 파지법으로 젓가락을 잡고 물체를 재배치하자.

이에 논문에서는

-   모션 캡처 데이터나 인간의 시연이 필요하지 않음
-   파지법만 학습한다면 다양한 도구를 사용할 수 있음
-   다양한 Grip 스타일을 반자동으로 찾아냈음  
    이라는 contribution을 제시했다. 그중 가장 큰 것은 다양한 도구를 사용할 수 있다는 점이 아닐까.

---

## 방법론

![[Pasted image 20260228185501.png]]

전체적인 방법론은 이렇다.

Step1) 손에 젓가락을 얼마나 안정적으로 쥐느냐가 중요하므로 베이지안 최적화와 심층 강화학습을 결합하여 이를 찾아냈다. 젓가락을 쥐는 다양한 스타일을 찾아내는 과정이다.

Step2) 물리 시뮬레이션을 돌리기 전, 기하학적으로 가능한 최적의 궤적을 먼저 생성한다. 여기서 손, 팔, 젓가락, 시간에 따른 물체의 좌표값 등을 Low-level에 전달해준다.

Step3) High-level에서 만든 경로를 MoJoCo 안에서 구현한다. 이때 경로를 따라감과 동시에 손가락이 젓가락에서 미끄러지지 않아야 한다.

### Step1. Gripping Pose Optimization

젓가락을 쥐는 다양한 스타일을 찾아내는 과정이다.

![[Pasted image 20260228185510.png]]

먼저 파지 스타일을 정의해준다. 5개의 손가락이 각각 어떤 젓가락(1번, 2번, 혹은 허공)과 접촉할지를 5개의 숫자 조합으로 정의한다. 그럼 튜플 형태의 C가 만들어진다.그 다음은 접촉 위치를 알아내야 한다. 그런데 이때 어떤 접촉점이 좋을지 알 수가 없으므로 베이지안 최적화 알고리즘을 사용하여 하나하나 실험을 해본다. x(a,b,c,d,e)로 결정하고 실험을 돌리면 보상(reward)가 나올텐데, 그렇게 실험을 하면서 이번에는 어떤 x 조합을 사용할지를 결정하게 도와주는 알고리즘이라고 보면 된다.만약 contact position을 정했다면, Inverse Kinematic을 이용해 Gripping pose를 출력한다. 그리고 그 상태로 시뮬레이션을 돌려서 해당 contact position을 썻을 경우 얼마나 보상을 받을수 있는지 알아내면 된다. 아직 high-level에서 궤적을 받지 못했으므로 세 가지의 1초 길이짜리 동작을 따라하는 (궤적을 따라가는) task를 수행했고 아래와 같은 보상 함수를 통해 reward를 얻는다.

$$r=exp(r_{hand}+r_{chop}+r_{contact})$$

![[Pasted image 20260228185546.png]]

### Step2. High-level motion planning

기하학적으로 가능한 최적의 궤적을 생성하는 것
![[Pasted image 20260228185554.png]]

**Grasping model**: Neural 기반 모델을 통해 물체의 모양과 위치에 맞춰 젓가락을 어느 각도로 벌려 잡아야 할지 최적의 구성 추천받음. 사전 학습된 신경망이 사용된다.

-   Configuration Network: 입력된 물체의 모양을 보고 젓가락의 배치 후보 제안
    -   입력 데이터: 잡으려는 물체의 모양과 크기 정보
    -   출력 데이터: 물체의 로컬 좌표계 기준으로 파지에 적합한 젓가락 구성 후보들을 지명. 각 후보가 성공할 확률도 내놓음. 여기서 해당 데이터는 시연 데이터가 아닌 합성 데이터를 자체적으로 생성하여 지도 학습으로 훈련시켰다. 각 물체에 대해 입자 군집 최적화(Particle Swarm Optimization, PSO) 알고리즘을 실행하여 최적의 젓가락 파지 설정(Grasping Configuration)을 찾은 것. 최적화 기준은 젓가락 끝을 잇는 선의 중심이 물체의 질량 중심에 가깝고, 그 선의 방향이 접촉면의 법선과 정렬되도록 하는 물리적 기준을 사용했고, 이렇게 PSO로 찾아낸 최적의 설정들을 미리 정의된 이산화된 설정 공간(2000개)에 매핑하여 ㅅ해당 설정을 정답(성공 확률1)으로 라벨링 해놓은 것이다.
-   Reachability Network: 제안된 파지 자세가 실제 로봇의 가동 범위 내에 있는가?
    -   입력: 제안 후보들을 global 좌표계로 변환한 데이터가 입력
    -   출력: 현재 시뮬레이션 중인 손과 팔의 도달 가능한 공간 안에 있을 가능성 추정

![[Pasted image 20260228185605.png]]

참고로 이때 젓가락의 DoF는 7개로 줄어든다. High-level에서 궤적을 보다 쉽게 찾기 위함.
![[Pasted image 20260228185647.png]]

그러고 나면 이제 **Trajectory Generation** 차례. 최단 궤적을 최적화 알고리즘으로 계산한다.

-   관절의 구성: 손, 팔, 젓가락, 그리고 조작할 물체의 위치와 방향 정보
-   관절 위치와의 관계: IK 이용해서 궤적 구현을 위한 손과 팔의 관절 각도를 역산
-   결과물: 손, 팔, 젓가락, 그리고 물체가 시간에 따라 있어야 할 좌표값을 하위 제어기에 전달함.

> **Q. Trejctory Optimization을 통해서 손 관절의 궤적을 전부 뽑아낸 것인가?**  
> \- 전부 뽑아낸 것이 맞음. trajectory Opimization 전에 특정 gripping pose를 가정함. 실질적 output은 젓가락 궤도 뿐이지만 IK 이용해서 손목이랑 손가락 관절 trajectory까지 전부 뽑아냄.  
> \- low level 상황에서 특정 gripping pose를 기본값으로 가지고 학습을 시작함  
> \- (모순 발생) 사실 low-level controller 입장에서는 손가락 고정하니(r\_hand) 젓가락 궤적을 따라가지 못하고(r\_chop), 젓가락을 따라가자니 손가락 참조값을 생각해야 함.  
> \- 그래서 논문에서는 가중치를 사용함. 논문은 젓가락 궤적 추종 보장(r\_chop)에 가중치 30점을 줬지만 손 자세 추종 보상(r\_hand)에는 가중치 10만 부여함.  
> \=> 결론: 모두 뽑는다!  
>   
> **그럼 왜 그랬을까?**  
>   
> 저자들은 그냥 가능한 해를 물리적으로 잘 따라가도록 재현하는 문제로 둔 것 아닐까 싶다.  
> 이 논문은 그냥 사람과 비슷한 gripping style을 유지하면서 젓가락 물체 옮기기가 가능합니다!를 말하고 싶은 거라 로봇 손이 '특정 gripping style'을 유지하고 있어야 한다는 보장이 필요했고, 그래서 trajectory를 전부 뽑아낸 것. 그냥 옮기기가 아니라 다양한 gripping style로 옮기기! 니까.

### Step3. Low-level hand control

상위 단계에서 만든 경로를 MuJoCo 안에서 PPO 알고리즘을 돌려서 구현하는 단계.

-   입력  
    -   시뮬레이션 상태: 손, 젓가락, 물체의 현재 위치 및 속도
    -   접촉 정보: 손가락 끝과 젓가락 사이 거리와 힘, 젓가락과 물체 사이의 힘
        
    -   미래 궤적: high-level에서 생성한 향후 6프레임 동안의 목표 상태
        

> **🫠 보상함수!**  
> $$r=exp(r_{hand}+r_{chop}+r_{object}+r_{contact})$$
> \- 실제 손 관절 위치가 계획된 경로와 얼마나 일치하는가?  
> \- 두 개의 젓가락 위치와 방향이 목표 궤적을 잘 따라가는가?  
> \- 조작 대상인 물체가 의도한 위치와 방향으로 움직이는가?  
> \- 손가락 끝이 젓가락의 지정된 접촉 지점에서 떨어지거나 미끄러지지 않도록 유도  
> \- 가중치는 chop = obj = 40 > hand = contact = 10  
>    - 때문에 high-level이 만들어준 chopstick과 object의 궤적을 따라가는 것에 더 초점이 맞춰져 있어, 손 관절의 어긋남은 어느 정도 허용해준다.

---

## Results
![[Pasted image 20260228185734.png]]

Ablation Test상으로는 사람이 직접 좋은 자세를 직접 지정해준 것보다 해당 방법의 reward 값이 더 좋았음

그런데 high-level을 생략한 실험은 불공평하다고 할 수도 있을 것 같다. 애초에 이 논문의 low-level 친구는  high-level 친구가 만들어준 궤적을 '따라가는 것'으로만 학습되어 있으니까.
![[Pasted image 20260228185742.png]]

그 외 다양한 물건과 손으로도 같은 일을 수행할 수 있음을 보였다. 아마도 이 점이 가장 강력한 Wow 포인트가 아닐까 싶다.